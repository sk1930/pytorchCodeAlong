{"cells":[{"cell_type":"markdown","metadata":{"id":"jHZHUBr2jmYX"},"source":["# Full Artificial Neural Network Code Along\n","The goal is to estimate the cost of a New York City cab ride from several inputs. The inspiration behind this code along is a recent <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>Kaggle competition</a>.\n","\n","<div class=\"alert alert-success\"><strong>NOTE:</strong> In this notebook we'll perform a regression with one output value. In the next one we'll perform a binary classification with two output values.</div>\n","\n","## Working with tabular data\n","Deep learning with neural networks is often associated with sophisticated image recognition, and in upcoming sections we'll train models based on properties like pixels patterns and colors.\n","\n","Here we're working with tabular data (spreadsheets, SQL tables, etc.) with columns of values that may or may not be relevant. As it happens, neural networks can learn to make connections we probably wouldn't have developed on our own. However, to do this we have to handle categorical values separately from continuous ones.\n","* continuous vs. categorical values\n","* embeddings\n","* batch normalization\n","* dropout layers"]},{"cell_type":"markdown","metadata":{"id":"u2-IGrNdjmYc"},"source":["## Perform standard imports"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"xKLDzbLdjmYc","executionInfo":{"status":"ok","timestamp":1696562589094,"user_tz":240,"elapsed":5544,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"9TgCQKT6jmYe"},"source":["## Load the NYC Taxi Fares dataset\n","The <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>Kaggle competition</a> provides a dataset with about 55 million records. The data contains only the pickup date & time, the latitude & longitude (GPS coordinates) of the pickup and dropoff locations, and the number of passengers.\n","\n","> For instance, does the time of day matter? The day of the week? How do we determine the distance traveled from pairs of GPS coordinates?\n","\n","\n","> an artificial neural network can really only take in straight numerical data and it's not going to be able to understand direct complex data such as a full date timestamp.\n","So a full date timestamp contains as a string code, or at least it looks kind of like a string code. Things like the year, the month, the date, the hour, the minute, the second. A network just can't take in that data raw.\n","What you need to do is you need to use feature engineering to separate it out into useful components, things like Am versus PM or the hour of the day on a 24 hour clock. So then it's a value between 0 and 24.\n","\n","> we need to do the same thing for things like longitude and latitude measurements. You could try to just pass those in in their raw format, longitude and latitude, but then you'll have to have a really large network because the network would have to try to learn the relationship between longitude and latitude.\n","\n","> And then there's the added complexity of latitude and longitude. Since it's determined on the equator, there may be issues with things being positive and negative.\n","\n","> And also then you have issues of things like the actual resolution of that latitude and longitude. If you're doing all your pick up and drop offs within the same city, essentially the significant digits beyond that decimal point are going to be really substantial because latitude and longitude doesn't change much within the distance of a city. You're looking at changes of maybe 0.001 scale.\n","\n","Lets calculate distance from GPS coordinates, and how to create a pandas datatime object from a text column. This will let us quickly get information like day of the week, am vs. pm, etc.\n","\n","\n","\n","\n","1.   pickup_datetime - timestamp value indicating when the taxi ride started.\n","2. pickup_longitude - float for longitude coordinate of where the taxi ride started.\n","3. pickup_latitude - float for latitude coordinate of where the taxi ride started.\n","4. dropoff_longitude - float for longitude coordinate of where the taxi ride ended.\n","5. dropoff_latitude - float for latitude coordinate of where the taxi ride ended.\n","6. passenger_count - integer indicating the number of passengers in the taxi ride.\n","\n","7. Target\n","fare_amount - float dollar amount of the cost of the taxi ride. This value is only in the training set; this is what you are predicting in the test set and it is required in your submission CSV.\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1696562589361,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"mjq1sTggjmYf","outputId":"6d0d67f7-2a72-4a46-9290-edb51bf6e322"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n","0        40.730521         -73.975499         40.744746                1  \n","1        40.740558         -73.974232         40.744114                1  \n","2        40.751118         -73.960064         40.766235                2  \n","3        40.756422         -73.971205         40.748192                1  \n","4        40.734202         -73.905956         40.743115                1  "],"text/html":["\n","  <div id=\"df-9264bf47-03b7-451f-a417-eedec0afe883\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9264bf47-03b7-451f-a417-eedec0afe883')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9264bf47-03b7-451f-a417-eedec0afe883 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9264bf47-03b7-451f-a417-eedec0afe883');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c878f03e-784f-493c-9595-d3e0f8978027\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c878f03e-784f-493c-9595-d3e0f8978027')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c878f03e-784f-493c-9595-d3e0f8978027 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":2}],"source":["#df = pd.read_csv('../Data/NYCTaxiFares.csv')\n","\n","df = pd.read_csv('NYCTaxiFares.csv')\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1696562589570,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"iafFC8SYjmYg","outputId":"76e5f080-a0a3-47cc-99c1-839691224ac0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    120000.000000\n","mean         10.040326\n","std           7.500134\n","min           2.500000\n","25%           5.700000\n","50%           7.700000\n","75%          11.300000\n","max          49.900000\n","Name: fare_amount, dtype: float64"]},"metadata":{},"execution_count":3}],"source":["df['fare_amount'].describe()"]},{"cell_type":"markdown","metadata":{"id":"gQ_LVqGRjmYg"},"source":["From this we see that fares range from \\\\$2.50 to \\\\$49.90, with a mean of \\\\$10.04 and a median of \\\\$7.70"]},{"cell_type":"markdown","metadata":{"id":"g-mAblpBjmYh"},"source":["## Calculate the distance traveled\n","The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n","\n","Right now we only have direct longitudes and latitudes.\n","And if you were to train the network on the direct longitudes and latitudes, you would notice that\n","it doesn't actually perform that well.\n","There's a couple of reasons for that.\n","\n","One is because it's kind of difficult to interpret a direct longitude and latitude.\n","\n","Another reason for that is because within just New York City, there's not going to be extreme changes\n","in longitude and latitude, especially for shorter trips.\n","\n","And we can see here we're dealing with our particular data set just around a $10 trip, which isn't\n","a trip that's very long, which means if you take a look at these longitude changes, the longitude,\n","the actual significant digits, where you'd have to actually start seeing changes is pretty extreme.\n","It's beyond just these two decimal places.\n","So some of these if you're only to look at these first four digits, they would look exactly the same\n","between the pickup locations and the drop off locations.\n","So if we look at the drop off locations, you can see these are still at 73.9 something.\n","So that difference is an issue for us.\n","And what would probably be a better feature to actually take into account is the distance between the\n","pickup points and the drop off points.\n","And for that, we'll need to actually figure out how we calculate the distance traveled from two setsof GPS coordinates.\n","\n","\n","Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n","\n","The distance formula works out to\n","\n","${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2    r = 6371 })\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n","\n","where\n","\n","$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n","\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n","\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{split}$"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1696562589570,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"TTfE62I0tfbd","outputId":"f6616af5-c7aa-43aa-d39b-fcd604897e64"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.126311585679373"]},"metadata":{},"execution_count":4}],"source":["r = 6371\n","long1 = -73.992365\n","lat1 = 40.730521\n","long2 = -73.975499\n","lat2 = 40.744746\n","\n","phi1 = np.radians(lat1)\n","phi2 = np.radians(lat2)\n","\n","delta_phi = np.radians(lat2-lat1)\n","delta_lambda = np.radians(long2-long1)\n","\n","a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","d = 2 * r* np.arcsin(np.sqrt(a))\n","d"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8kl_e-wDxiZK","executionInfo":{"status":"ok","timestamp":1696562589570,"user_tz":240,"elapsed":28,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1696562589571,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"SfdbVVE-unrY","outputId":"15688907-7217-485d-9c43-519f486f8b91"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.126311585679373"]},"metadata":{},"execution_count":5}],"source":["r = 6371\n","long1 = -73.992365\n","lat1 = 40.730521\n","long2 = -73.975499\n","lat2 = 40.744746\n","\n","phi1 = np.radians(lat1)\n","phi2 = np.radians(lat2)\n","\n","delta_phi = np.radians(lat2-lat1)\n","delta_lambda = np.radians(long2-long1)\n","\n","a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n","d = (r * c) # in kilometers\n","d"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696562589571,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"MUWcMUS5xjQ7","outputId":"2d1ff159-54c7-4c32-ae15-d6d11c21b369"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["140.13249913646146"]},"metadata":{},"execution_count":6}],"source":["\n","np.arccos(np.sin(lat1)*np.sin(lat2)+np.cos(lat1)*np.cos(lat2)*np.cos(long2-long1))*6371"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"id":"5NZ0KH2ujmYh","executionInfo":{"status":"ok","timestamp":1696562589571,"user_tz":240,"elapsed":18,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["def haversine_distance(df, lat1, long1, lat2, long2):\n","    \"\"\"\n","    Calculates the haversine distance between 2 sets of GPS coordinates in df\n","    \"\"\"\n","    r = 6371  # average radius of Earth in kilometers\n","\n","    phi1 = np.radians(df[lat1])\n","    phi2 = np.radians(df[lat2])\n","\n","    delta_phi = np.radians(df[lat2]-df[lat1])\n","    delta_lambda = np.radians(df[long2]-df[long1])\n","\n","    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n","    d = (r * c) # in kilometers\n","\n","    return d"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696562589571,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"xb3v1KjGjmYh","outputId":"8c0ed0cd-83a0-4c26-a5c4-6959d53a8dea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n","0        40.730521         -73.975499         40.744746                1   \n","1        40.740558         -73.974232         40.744114                1   \n","2        40.751118         -73.960064         40.766235                2   \n","3        40.756422         -73.971205         40.748192                1   \n","4        40.734202         -73.905956         40.743115                1   \n","\n","    dist_km  \n","0  2.126312  \n","1  1.392307  \n","2  3.326763  \n","3  1.864129  \n","4  7.231321  "],"text/html":["\n","  <div id=\"df-577f2ef8-736d-426a-84cd-9cf528789757\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","      <th>dist_km</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","      <td>2.126312</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","      <td>1.392307</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","      <td>3.326763</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","      <td>1.864129</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","      <td>7.231321</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-577f2ef8-736d-426a-84cd-9cf528789757')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-577f2ef8-736d-426a-84cd-9cf528789757 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-577f2ef8-736d-426a-84cd-9cf528789757');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ff4deaf9-4729-41df-be07-dafeedfe906b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff4deaf9-4729-41df-be07-dafeedfe906b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ff4deaf9-4729-41df-be07-dafeedfe906b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"Yg6PVosTjmYi"},"source":["## Add a datetime column and derive useful statistics\n","By creating a datetime object, we can extract information like \"day of the week\", \"am vs. pm\" etc.\n","Note that the data was saved in UTC time. Our data falls in April of 2010 which occurred during Daylight Savings Time in New York. For that reason, we'll make an adjustment to EDT using UTC-4 (subtracting four hours)."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CUKtqbtd3f5r","executionInfo":{"status":"ok","timestamp":1696562605303,"user_tz":240,"elapsed":15748,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["x = pd.to_datetime(df['pickup_datetime'])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2Y6vNim_3yNy","executionInfo":{"status":"ok","timestamp":1696562605307,"user_tz":240,"elapsed":50,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["my_time  = x[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1696562605307,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"DrmrzWxZ32ln","outputId":"59dd45d0-dfe4-42a9-9107-a0981c2cf041"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Timestamp('2010-04-19 08:17:56+0000', tz='UTC')"]},"metadata":{},"execution_count":11}],"source":["my_time"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1696562605307,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"-GsGi1Rz33mq","outputId":"ac305ed7-777b-48f8-f24d-0a7b79d2e939"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["109"]},"metadata":{},"execution_count":12}],"source":["#just type my_time. and wait and u will see lot of methods available\n","my_time.dayofyear"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2nlKFLNS4ypw","executionInfo":{"status":"ok","timestamp":1696562605307,"user_tz":240,"elapsed":30,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HXy7qgRu4zRa"},"source":["But what things do you think are important due to the date time stamp of the pickup and try to actually extract those features because a neural network is not going to be able to understand this date time object, just put in straight.\n","Instead, what we need to do is do some feature engineering to actually extract those.\n","Recall that all of these taxi rides are occurring within New York City, which is on Eastern Standard Time.\n","But if we take a look back at this pickup date time stamp, right now, it's under UTC, which actually\n","means there's a four hour difference because due to our data, it's also falling in April.\n","And so if you take a look at some of these timestamps, actually, let's just call. Df.head.\n","These time stamps are occurring in April of 2010, and that actually occurred during daylight savings time.\n","\n","So there's a time delta or difference in time of four hours between this timestamp and the actual time it was in New York City when this pickup actually happened.\n","\n","So while this time is technically true, the there's a four hour difference for the actual passenger riding on the car.\n","\n","That's important because it lets us know things like if it was Am or PM. So we're going to have to take that into account.\n","\n","So let's go ahead and make sure that when we're calculating these things, we'll have an adjusted date by four hours.\n","And one way we can easily do that is by simply creating a new column, we'll say DF EDT date so that Eastern time will be equal to.\n"]},{"cell_type":"code","source":["df['pickup_datetime'][0]"],"metadata":{"id":"94OtiF7TkJGU","executionInfo":{"status":"ok","timestamp":1696562605307,"user_tz":240,"elapsed":27,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"f21c9e75-108f-4333-e4df-44480bc855d9","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2010-04-19 08:17:56 UTC'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df['pickup_datetime'][0][:19]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NeaCQJxzj3bC","executionInfo":{"status":"ok","timestamp":1696562605307,"user_tz":240,"elapsed":23,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"74524ba0-eb54-4207-a4f8-d7ca11e9c136"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2010-04-19 08:17:56'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":726,"status":"ok","timestamp":1696562606014,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"eU5_p0Zi4BBx","outputId":"08f0d40a-bcdf-41d3-b81e-744256809f31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n","0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n","1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n","2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n","3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n","4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n","\n","   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n","0        40.730521         -73.975499         40.744746                1   \n","1        40.740558         -73.974232         40.744114                1   \n","2        40.751118         -73.960064         40.766235                2   \n","3        40.756422         -73.971205         40.748192                1   \n","4        40.734202         -73.905956         40.743115                1   \n","\n","    dist_km             EDTdate  Hour AMorPM Weekday  \n","0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n","1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n","2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n","3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n","4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "],"text/html":["\n","  <div id=\"df-24ee0dc1-f738-4c36-bf22-4d1d6236df14\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pickup_datetime</th>\n","      <th>fare_amount</th>\n","      <th>fare_class</th>\n","      <th>pickup_longitude</th>\n","      <th>pickup_latitude</th>\n","      <th>dropoff_longitude</th>\n","      <th>dropoff_latitude</th>\n","      <th>passenger_count</th>\n","      <th>dist_km</th>\n","      <th>EDTdate</th>\n","      <th>Hour</th>\n","      <th>AMorPM</th>\n","      <th>Weekday</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2010-04-19 08:17:56 UTC</td>\n","      <td>6.5</td>\n","      <td>0</td>\n","      <td>-73.992365</td>\n","      <td>40.730521</td>\n","      <td>-73.975499</td>\n","      <td>40.744746</td>\n","      <td>1</td>\n","      <td>2.126312</td>\n","      <td>2010-04-19 04:17:56</td>\n","      <td>4</td>\n","      <td>am</td>\n","      <td>Mon</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2010-04-17 15:43:53 UTC</td>\n","      <td>6.9</td>\n","      <td>0</td>\n","      <td>-73.990078</td>\n","      <td>40.740558</td>\n","      <td>-73.974232</td>\n","      <td>40.744114</td>\n","      <td>1</td>\n","      <td>1.392307</td>\n","      <td>2010-04-17 11:43:53</td>\n","      <td>11</td>\n","      <td>am</td>\n","      <td>Sat</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2010-04-17 11:23:26 UTC</td>\n","      <td>10.1</td>\n","      <td>1</td>\n","      <td>-73.994149</td>\n","      <td>40.751118</td>\n","      <td>-73.960064</td>\n","      <td>40.766235</td>\n","      <td>2</td>\n","      <td>3.326763</td>\n","      <td>2010-04-17 07:23:26</td>\n","      <td>7</td>\n","      <td>am</td>\n","      <td>Sat</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2010-04-11 21:25:03 UTC</td>\n","      <td>8.9</td>\n","      <td>0</td>\n","      <td>-73.990485</td>\n","      <td>40.756422</td>\n","      <td>-73.971205</td>\n","      <td>40.748192</td>\n","      <td>1</td>\n","      <td>1.864129</td>\n","      <td>2010-04-11 17:25:03</td>\n","      <td>17</td>\n","      <td>pm</td>\n","      <td>Sun</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2010-04-17 02:19:01 UTC</td>\n","      <td>19.7</td>\n","      <td>1</td>\n","      <td>-73.990976</td>\n","      <td>40.734202</td>\n","      <td>-73.905956</td>\n","      <td>40.743115</td>\n","      <td>1</td>\n","      <td>7.231321</td>\n","      <td>2010-04-16 22:19:01</td>\n","      <td>22</td>\n","      <td>pm</td>\n","      <td>Fri</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24ee0dc1-f738-4c36-bf22-4d1d6236df14')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-24ee0dc1-f738-4c36-bf22-4d1d6236df14 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-24ee0dc1-f738-4c36-bf22-4d1d6236df14');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b1be410-224a-4bac-a676-201a209d9105\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b1be410-224a-4bac-a676-201a209d9105')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b1be410-224a-4bac-a676-201a209d9105 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}],"source":["df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n","df['Hour'] = df['EDTdate'].dt.hour\n","df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n","df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n","df.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"lAy1i7v8jmYi","executionInfo":{"status":"ok","timestamp":1696562606015,"user_tz":240,"elapsed":41,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1696562606015,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"ROVkgcrgjmYj","outputId":"2afe2cca-ba17-4140-d69d-dff7fe983bee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Timestamp('2010-04-11 00:00:10')"]},"metadata":{},"execution_count":16}],"source":["df['EDTdate'].min()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1696562606015,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"lZiUOziljmYj","outputId":"574439d7-65a2-4f9e-c711-25bd95f41a52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Timestamp('2010-04-24 23:59:42')"]},"metadata":{},"execution_count":17}],"source":["df['EDTdate'].max()"]},{"cell_type":"markdown","metadata":{"id":"TCw_lGGijmYj"},"source":["## Separate categorical from continuous columns"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696562606015,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"6oIlTeQljmYj","outputId":"b952ccea-ca54-49e9-fc07-648fb16d7383"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n","       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n","       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n","      dtype='object')"]},"metadata":{},"execution_count":18}],"source":["df.columns"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1696562606015,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"Db9e0OEh_khk","outputId":"0a21c595-85a5-42cb-e3a3-b51f2f01b25d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["pickup_datetime              object\n","fare_amount                 float64\n","fare_class                    int64\n","pickup_longitude            float64\n","pickup_latitude             float64\n","dropoff_longitude           float64\n","dropoff_latitude            float64\n","passenger_count               int64\n","dist_km                     float64\n","EDTdate              datetime64[ns]\n","Hour                          int64\n","AMorPM                       object\n","Weekday                      object\n","dtype: object"]},"metadata":{},"execution_count":19}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":true,"id":"XDEqwaEOjmYk","executionInfo":{"status":"ok","timestamp":1696562606016,"user_tz":240,"elapsed":12,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["cat_cols = ['Hour', 'AMorPM', 'Weekday']\n","cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n","y_col = ['fare_amount']  # this column contains the labels\n","# we will use the fare_class as y_col for classification problem"]},{"cell_type":"markdown","metadata":{"id":"5ud0Mki6jmYk"},"source":["<div class=\"alert alert-info\"><strong>NOTE:</strong> If you plan to use all of the columns in the data table, there's a shortcut to grab the remaining continuous columns:<br>\n","<pre style='background-color:rgb(217,237,247)'>cont_cols = [col for col in df.columns if col not in cat_cols + y_col]</pre>\n","\n","Here we entered the continuous columns explicitly because there are columns we're not running through the model (pickup_datetime and EDTdate)</div>\n"]},{"cell_type":"markdown","metadata":{"id":"Ej_5CM57jmYk"},"source":["## Categorify\n","Pandas offers a <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category dtype</strong></a> for converting categorical values to numerical codes. A dataset containing months of the year will be assigned 12 codes, one for each month. These will usually be the integers 0 to 11. Pandas replaces the column values with codes, and retains an index list of category values. In the steps ahead we'll call the categorical values \"names\" and the encodings \"codes\"."]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true,"id":"fJTTxc7tjmYk","executionInfo":{"status":"ok","timestamp":1696562606016,"user_tz":240,"elapsed":11,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["# Convert our three categorical columns to category dtypes.\n","for cat in cat_cols:\n","    df[cat] = df[cat].astype('category')"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"oZppJdYIjmYl","outputId":"432427c3-0d19-4a8b-ba8e-4e89b51be40e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["pickup_datetime              object\n","fare_amount                 float64\n","fare_class                    int64\n","pickup_longitude            float64\n","pickup_latitude             float64\n","dropoff_longitude           float64\n","dropoff_latitude            float64\n","passenger_count               int64\n","dist_km                     float64\n","EDTdate              datetime64[ns]\n","Hour                       category\n","AMorPM                     category\n","Weekday                    category\n","dtype: object"]},"metadata":{},"execution_count":22}],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"KoNPpXI7jmYl"},"source":["We can see that <tt>df['Hour']</tt> is a categorical feature by displaying some of the rows:"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"lyM2gb1LjmYl","outputId":"a92ef442-7d19-4804-a96e-90f251b68cd1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     4\n","1    11\n","2     7\n","3    17\n","4    22\n","Name: Hour, dtype: category\n","Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"]},"metadata":{},"execution_count":23}],"source":["df['Hour'].head()"]},{"cell_type":"markdown","metadata":{"id":"MUdDPAIyjmYl"},"source":["Here our categorical names are the integers 0 through 23, for a total of 24 unique categories. These values <em>also</em> correspond to the codes assigned to each name.\n","\n","We can access the category names with <tt>Series.cat.categories</tt> or just the codes with <tt>Series.cat.codes</tt>. This will make more sense if we look at <tt>df['AMorPM']</tt>:"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"3-jeFi19jmYm","outputId":"20c62253-d85a-45a6-c905-731c57fe072d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    am\n","1    am\n","2    am\n","3    pm\n","4    pm\n","Name: AMorPM, dtype: category\n","Categories (2, object): ['am', 'pm']"]},"metadata":{},"execution_count":24}],"source":["df['AMorPM'].head()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"uf2LQ9FjjmYm","outputId":"d5cef5d5-8fe2-430d-f628-cf19278cb318"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['am', 'pm'], dtype='object')"]},"metadata":{},"execution_count":25}],"source":["df['AMorPM'].cat.categories"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"PeBUiqSEjmYm","outputId":"83877277-3d54-48d3-eb89-ca25d8b067f3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0\n","1    0\n","2    0\n","3    1\n","4    1\n","dtype: int8"]},"metadata":{},"execution_count":26}],"source":["df['AMorPM'].head().cat.codes"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"Wt4StfuUjmYm","outputId":"6527dc65-f879-4e09-8f82-c72c72c1dc67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"]},"metadata":{},"execution_count":27}],"source":["df['Weekday'].cat.categories"]},{"cell_type":"code","source":["df['Weekday'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrLgW9p_1CWi","executionInfo":{"status":"ok","timestamp":1696562606268,"user_tz":240,"elapsed":20,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"0275bacf-8672-4e1a-b962-b13f68bd05be"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Mon\n","1    Sat\n","2    Sat\n","3    Sun\n","4    Fri\n","Name: Weekday, dtype: category\n","Categories (7, object): ['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1696562606268,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"PJJSfIo2jmYn","outputId":"76de35c7-cbfb-4b7c-cb90-fc5b6cdf7374"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    1\n","1    2\n","2    2\n","3    3\n","4    0\n","dtype: int8"]},"metadata":{},"execution_count":29}],"source":["df['Weekday'].head().cat.codes"]},{"cell_type":"markdown","metadata":{"id":"wSIDyxExjmYn"},"source":["<div class=\"alert alert-info\"><strong>NOTE: </strong>NaN values in categorical data are assigned a code of -1. We don't have any in this particular dataset.</div>"]},{"cell_type":"markdown","metadata":{"id":"HeKLr6ybjmYn"},"source":["Now we want to combine the three categorical columns into one input array using <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a> We don't want the Series index, just the values.\n","\n","\n","And recall that when we're turning things into tensors, we first need them in a numpy array format and then we can cast them into a pytorch tensor."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1696562606269,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"LDQpO1S-QZF0","outputId":"bc700150-0ae7-4050-b0f5-9120a025f3c9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 4, 11,  7, ..., 14,  4, 12], dtype=int8)"]},"metadata":{},"execution_count":30}],"source":["df['Hour'].cat.codes.values # to get numpy array"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1696562606269,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"55M20AIdjmYn","outputId":"163a5bfe-82bb-42df-b866-e1c5ed0204bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 4,  0,  1],\n","       [11,  0,  2],\n","       [ 7,  0,  2],\n","       [17,  1,  3],\n","       [22,  1,  0]], dtype=int8)"]},"metadata":{},"execution_count":31}],"source":["hr = df['Hour'].cat.codes.values\n","ampm = df['AMorPM'].cat.codes.values\n","wkdy = df['Weekday'].cat.codes.values\n","\n","cats = np.stack([hr, ampm, wkdy],axis=1)\n","\n","cats[:5]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"T3CUBprASKaG","executionInfo":{"status":"ok","timestamp":1696562606273,"user_tz":240,"elapsed":16,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6QnLC98ZjmYo"},"source":["<div class=\"alert alert-info\"><strong>NOTE:</strong> This can be done in one line of code using a list comprehension:\n","<pre style='background-color:rgb(217,237,247)'>cats = np.stack([df[col].cat.codes.values for col in cat_cols], axis = 1)</pre>\n","\n","Don't worry about the dtype for now, we can make it int64 when we convert it to a tensor.</div>\n"]},{"cell_type":"markdown","metadata":{"id":"XIJuPmX5jmYo"},"source":["## Convert numpy arrays to tensors"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1696562606485,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"O1KypF0SjmYo","outputId":"e2f72440-c296-4307-929d-4625262eee2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4,  0,  1],\n","        [11,  0,  2],\n","        [ 7,  0,  2],\n","        [17,  1,  3],\n","        [22,  1,  0]])"]},"metadata":{},"execution_count":32}],"source":["# Convert categorical variables to a tensor\n","cats = torch.tensor(cats, dtype=torch.int64)\n","# this syntax is ok, since the source data is an array, not an existing tensor\n","\n","cats[:5]"]},{"cell_type":"markdown","metadata":{"id":"3q08b-BqjmYo"},"source":["We can feed all of our continuous variables into the model as a tensor. Note that we're not normalizing the values here; we'll let the model perform this step.\n","<div class=\"alert alert-info\"><strong>NOTE:</strong> We have to store <tt>conts</tt> and <tt>y</tt> as Float (float32) tensors, not Double (float64) in order for batch normalization to work properly.</div>"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1696562606485,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"3fGhBDk6jmYo","outputId":"f6b9b074-9d1f-4b46-f37a-851b4d94ee01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n","        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n","        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n","        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n","        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"]},"metadata":{},"execution_count":33}],"source":["# Convert continuous variables to a tensor\n","conts = np.stack([df[col].values for col in cont_cols], axis = 1)\n","conts = torch.tensor(conts, dtype=torch.float)\n","conts[:5]"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1696562606485,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"IavxrFMojmYp","outputId":"24bcc13f-6b10-458d-fb2d-669b2b2e5142"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'torch.FloatTensor'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}],"source":["conts.type()"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1696562606486,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"fNA91KbjjmYp","outputId":"1f2e6bab-3ad6-4b8f-ce44-9a01dd5bab7b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 6.5000],\n","        [ 6.9000],\n","        [10.1000],\n","        [ 8.9000],\n","        [19.7000]])"]},"metadata":{},"execution_count":35}],"source":["# Convert labels to a tensor\n","y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n","# for categorical output we are not reshaping and also we r not one hot encoding as we are using categorical cross entropy as loss\n","# for continuous  output we are reshaping to get [[op1],[op2],.....[opn]]\n","\n","y[:5]"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1696562606486,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"LpkGpGIsjmYq","outputId":"3cd35582-31cc-4125-cb48-a719559f2f7d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([120000, 3])"]},"metadata":{},"execution_count":36}],"source":["cats.shape"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1696562606486,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"8IXP4MIPjmYr","outputId":"aa753447-ae86-4648-eba2-2732e8fca743"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([120000, 6])"]},"metadata":{},"execution_count":37}],"source":["conts.shape"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1696562606486,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"AD_LgJ4hjmYr","outputId":"70396fb8-055d-43df-ee0d-226489aa8678"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([120000, 1])"]},"metadata":{},"execution_count":38}],"source":["y.shape"]},{"cell_type":"markdown","metadata":{"id":"mwEVWIFsjmYr"},"source":["https://www.quora.com/What-does-PyTorch-Embedding-do     --Prasoon Goyal\n","\n","## Set an embedding size\n","The rule of thumb for determining the embedding size is to divide the number of unique entries in each column by 2, but not to exceed 50.\n","Every deep learning framework has such an embedding layer. Let’s see why it is useful.\n","\n","Suppose you are working with images. An image is represented as a matrix of RGB values. Each RGB value is a feature that is numerical, that is, values 5 and 10 are closer than values 5 and 100. This information is implicitly used by the network to identify which images are close to each other, by comparing their individual pixel values.\n","\n","Now, let’s say you are working with text, in particular, sentences. Each sentence is composed of words, which are categorical variables, not numerical. How would you feed a word to a NN? One way to do this is to use one-hot vectors, wherein, you decide on the set of all words you will use [the “vocabulary”]. Let’s say your vocabulary has 10000 words, and you have defined an ordering over these words — “a”, “the”, “they”, “are”, “have”, etc. Now, you can represent the first word in the ordering [“a”] as [1, 0, 0, 0, ….], which is a vector of size 10000 with all zeros except a 1 at position 1. Similarly, the second, third, …, words can be defined as [0, 1, 0, 0, ….], [0, 0, 1, 0, ….], … So, the  ith\n","  word will be a vector of size 10,000 with all zeros, except a 1 at the  ith\n","  position. Now, we have a way to feed the words into the NN. But the notion of distance that we had in case of images is not present. All words are equidistant from all other words. Secondly, the dimension of the input is huge. Your vocabulary size could easily go to 100,000 or more.\n","\n","Therefore, instead of having a sparse vector for each word, you can have a dense vector for each word, that is, multiple elements of the vector are nonzero and each element of the vector can take continuous values. This immediately reduces the size of the vector. You can have infinite number of unique vectors of size, say 10, where each element can take any arbitrary value [as opposed to one-hot vectors where each element could take only values 0 or 1]. So, for instance, “a” could be represented as [0.13, 0.46, 0.85, 0.96, 0.66, 0.12, 0.01, 0.38, 0.76, 0.95], “the” could be represented as [0.73, 0.45, 0.25, 0.91, 0.06, 0.16, 0.11, 0.36, 0.76, 0.98], and so on. The size of the vectors is a hyperparameter, set using cross-validation. So, how do you feed these dense vector representations of words into the network? The answer is an embedding layer — you will have an embedding layer that is essentially a matrix of size 10,000 x 10 [or more generally,  vocab_size×dense_vector_size\n"," ].\n","\n","\n","\n"," For every word, you have an index in the vocabulary, like “a” -> 0, “the” -> 1, etc., and you simply look up the corresponding row in the embedding matrix to get its 10-dimensional representation as the output.\n","\n","\n","\n","Now, the embedding layer could be fixed, so that you don’t train it when you train the NN. This could be done, for instance, when you initialize your embedding layer using pretrained word vectors for the words.\n","\n","\n","\n","Alternately, you can initialize the embedding layer randomly, and train it with the other layers. Finally, you could do both — initialize with the word vectors and finetune on the task. In any case, the embeddings of similar words are similar, solving the issue we had with one-hot vectors."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1696562606486,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"-J71a7JlhAYL","outputId":"d8508e5d-c11a-457b-a930-3eac3657acbd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hour', 'AMorPM', 'Weekday']"]},"metadata":{},"execution_count":39}],"source":["cat_cols"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1696562606715,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"OUihfFZcjmYs","outputId":"1caed788-ce84-4b25-c742-75fedfd6f409"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(24, 12), (2, 1), (7, 4)]"]},"metadata":{},"execution_count":40}],"source":["# This will set embedding sizes for Hours, AMvsPM and Weekdays\n","cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n","emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n","\n","emb_szs"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1696562606715,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"yGmH2PMJhEKo","outputId":"80600520-0377-40e7-fabc-396a274cfb67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[24, 2, 7]"]},"metadata":{},"execution_count":41}],"source":["cat_szs"]},{"cell_type":"markdown","metadata":{"id":"KOXdMjvZjmYs"},"source":["## Define a TabularModel\n","This somewhat follows the <a href='https://docs.fast.ai/tabular.models.html'>fast.ai library</a> The goal is to define a model based on the number of continuous columns (given by <tt>conts.shape[1]</tt>) plus the number of categorical columns and their embeddings (given by <tt>len(emb_szs)</tt> and <tt>emb_szs</tt> respectively). The output would either be a regression (a single float value), or a classification (a group of bins and their softmax values). For this exercise our output will be a single regression value. Note that we'll assume our data contains both categorical and continuous data. You can add boolean parameters to your own model class to handle a variety of datasets."]},{"cell_type":"markdown","metadata":{"id":"KU96Hvq5jmYs"},"source":["<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take. See below for more detailed illustrations of the steps.</strong><br>\n","\n","1. Extend the base Module class, set up the following parameters:\n","   * <tt>emb_szs: </tt>list of tuples: each categorical variable size is paired with an embedding size\n","   * <tt>n_cont:  </tt>int: number of continuous variables\n","   * <tt>out_sz:  </tt>int: output size\n","   * <tt>layers:  </tt>list of ints: layer sizes\n","   * <tt>p:       </tt>float: dropout probability for each layer (for simplicity we'll use the same value throughout)\n","   \n","<tt><font color=black>class TabularModel(nn.Module):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self, emb_szs, n_cont, out_sz, layers, p=0.5):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n","\n","2. Set up the embedded layers with <a href='https://pytorch.org/docs/stable/nn.html#modulelist'><tt><strong>torch.nn.ModuleList()</strong></tt></a> and <a href='https://pytorch.org/docs/stable/nn.html#embedding'><tt><strong>torch.nn.Embedding()</strong></tt></a><br>Categorical data will be filtered through these Embeddings in the forward section.<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])</font></tt><br><br>\n","3. Set up a dropout function for the embeddings with <a href='https://pytorch.org/docs/stable/nn.html#dropout'><tt><strong>torch.nn.Dropout()</strong></tt></a> The default p-value=0.5<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.emb_drop = nn.Dropout(emb_drop)</font></tt><br><br>\n","\n","what a dropout layer does is during training, it's going to randomly zero some of the elements of the input tensor with some sort of probability that you provide.\n","So you by default, it's 50% probability.\n","But what this does is essentially randomly turns off 50% of the neurons, and that way you don't overfit.\n","It's a really common strategy.\n","\n","4. Set up a normalization function for the continuous variables with <a href='https://pytorch.org/docs/stable/nn.html#batchnorm1d'><tt><strong>torch.nn.BatchNorm1d()</strong></tt></a><br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)</font></tt><br><br>\n","\n"," we're also going to do is we want to normalize that continuous data to make sure it all falls within the same magnitude.\n","The order of magnitude range.\n","\n","5. Set up a sequence of neural network layers where each level includes a Linear function, an activation function (we'll use <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong>ReLU</strong></a>), a normalization step, and a dropout layer. We'll combine the list of layers with <a href='https://pytorch.org/docs/stable/nn.html#sequential'><tt><strong>torch.nn.Sequential()</strong></tt></a><br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;layerlist = []<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;n_emb = sum((nf for ni,nf in emb_szs))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;n_in = n_emb + n_cont<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;for i in layers:<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(n_in,i)) <br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.ReLU(inplace=True))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.BatchNorm1d(i))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Dropout(p))<br>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_in = i<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(layers[-1],out_sz))<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;self.layers = nn.Sequential(*layerlist)</font></tt><br><br>\n","6. Define the forward method. Preprocess the embeddings and normalize the continuous variables before passing them through the layers.<br>Use <a href='https://pytorch.org/docs/stable/torch.html#torch.cat'><tt><strong>torch.cat()</strong></tt></a> to combine multiple tensors into one.<br>\n","<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;def forward(self, x_cat, x_cont):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;embeddings = []<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;for i,e in enumerate(self.embeds):<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embeddings.append(e(x_cat[:,i]))<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat(embeddings, 1)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = self.emb_drop(x)<br>\n","<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x_cont = self.bn_cont(x_cont)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat([x, x_cont], 1)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;x = self.layers(x)<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;return x</font></tt>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"RWWgrTvfjmYt"},"source":["<div class=\"alert alert-danger\"><strong>Breaking down the embeddings steps</strong> (this code is for illustration purposes only.)</div>"]},{"cell_type":"code","source":["# help(nn.Embedding)"],"metadata":{"id":"mK7H9WtaG6V3","executionInfo":{"status":"ok","timestamp":1696562606715,"user_tz":240,"elapsed":34,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1696562606716,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"E7KH2pNAjmYt","outputId":"64757132-a9bc-450a-f95b-dc38af688e0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4,  0,  1],\n","        [11,  0,  2],\n","        [ 7,  0,  2],\n","        [17,  1,  3]])"]},"metadata":{},"execution_count":43}],"source":["# This is our source data\n","catz = cats[:4]\n","catz"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1696562606716,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"3Nsb5mjwjmYt","outputId":"b6faa9be-c99f-4ee0-d874-ffabc67ecee9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(24, 12), (2, 1), (7, 4)]"]},"metadata":{},"execution_count":44}],"source":["# This is passed in when the model is instantiated\n","emb_szs"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1696562606716,"user":{"displayName":"s k","userId":"03459268313336948614"},"user_tz":240},"id":"z20f3Rz9EIMp","outputId":"1eb8848e-980c-467b-d447-7e757e550e7b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Embedding(24, 12), Embedding(2, 1), Embedding(7, 4)]"]},"metadata":{},"execution_count":45}],"source":["[nn.Embedding(ni, nf) for ni,nf in emb_szs] # Creating a embedding layer"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"IPNRISDujmYu","outputId":"ce2541b1-7098-47ed-8efb-fdfab6d09e00","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562606716,"user_tz":240,"elapsed":18,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModuleList(\n","  (0): Embedding(24, 12)\n","  (1): Embedding(2, 1)\n","  (2): Embedding(7, 4)\n",")"]},"metadata":{},"execution_count":46}],"source":["# This is assigned inside the __init__() method\n","selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","selfembeds"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"OhyPT715jmYu","outputId":"99c3a058-5344-41f8-a442-abc7a60c5121","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562606716,"user_tz":240,"elapsed":15,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"]},"metadata":{},"execution_count":47}],"source":["list(enumerate(selfembeds))"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"ywVtDZLYjmYu","outputId":"9f94fa2b-d894-4178-c998-c562c038bee2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562606716,"user_tz":240,"elapsed":12,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[ 0.1677, -1.6355, -0.9113,  0.8843,  1.5710,  0.8027,  1.0104,  2.5019,\n","           1.2791,  0.6054,  1.3902, -0.4989],\n","         [-0.1508, -0.1471,  1.3686, -0.3555, -0.2774,  0.1099, -0.5506,  1.0596,\n","           0.3595,  0.4859, -1.6289, -0.6530],\n","         [-0.6778, -0.1558, -3.2439, -1.9364, -0.5427, -0.5546, -2.1623, -0.7389,\n","           0.9051,  0.0613, -0.6952, -2.4025],\n","         [ 0.7398, -0.7913, -0.9718,  1.3142, -0.6902,  0.5929, -2.2412, -0.3437,\n","           0.4038,  0.3001, -0.0516,  0.9254]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[0.6718],\n","         [0.6718],\n","         [0.6718],\n","         [0.6541]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[-0.6247, -1.5155,  0.3390, -1.1460],\n","         [-0.1082,  0.0500,  0.0956, -0.7517],\n","         [-0.1082,  0.0500,  0.0956, -0.7517],\n","         [ 1.1388,  0.3222,  1.2124,  0.4271]], grad_fn=<EmbeddingBackward0>)]"]},"metadata":{},"execution_count":48}],"source":["# This happens inside the forward() method\n","embeddingz = []\n","for i,e in enumerate(selfembeds):\n","    embeddingz.append(e(catz[:,i])) # by taking each column from all rows and getting a embedding tensor\n","embeddingz"]},{"cell_type":"markdown","source":["And then during the forward method, what actually happens is we end up applying values to each of those one hot encodings until eventually we start putting a lot of strength to maybe our number 12 in a day because that's lunchtime or PM because it's night and rides are going to be more expensive during night or maybe the last two of the weekdays, like Saturday and Sunday or the weekends, etcetera.\n","So we're actually then assigning numerical values to those one hot encodings that we created through\n","the embeddings.\n"],"metadata":{"id":"rfINYu6cQBwy"}},{"cell_type":"code","source":[],"metadata":{"id":"3JQZOE1sNhh6","executionInfo":{"status":"ok","timestamp":1696562606716,"user_tz":240,"elapsed":10,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","execution_count":49,"metadata":{"id":"SJ0GDd_ujmYu","outputId":"96827f54-96bc-45f3-83c5-21a872f1e922","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562606905,"user_tz":240,"elapsed":198,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1677, -1.6355, -0.9113,  0.8843,  1.5710,  0.8027,  1.0104,  2.5019,\n","          1.2791,  0.6054,  1.3902, -0.4989,  0.6718, -0.6247, -1.5155,  0.3390,\n","         -1.1460],\n","        [-0.1508, -0.1471,  1.3686, -0.3555, -0.2774,  0.1099, -0.5506,  1.0596,\n","          0.3595,  0.4859, -1.6289, -0.6530,  0.6718, -0.1082,  0.0500,  0.0956,\n","         -0.7517],\n","        [-0.6778, -0.1558, -3.2439, -1.9364, -0.5427, -0.5546, -2.1623, -0.7389,\n","          0.9051,  0.0613, -0.6952, -2.4025,  0.6718, -0.1082,  0.0500,  0.0956,\n","         -0.7517],\n","        [ 0.7398, -0.7913, -0.9718,  1.3142, -0.6902,  0.5929, -2.2412, -0.3437,\n","          0.4038,  0.3001, -0.0516,  0.9254,  0.6541,  1.1388,  0.3222,  1.2124,\n","          0.4271]], grad_fn=<CatBackward0>)"]},"metadata":{},"execution_count":49}],"source":["# We concatenate the embedding sections (12,1,4) into one (17)\n","z = torch.cat(embeddingz, axis = 1)\n","z"]},{"cell_type":"code","execution_count":50,"metadata":{"collapsed":true,"id":"qL7x1z1CjmYv","executionInfo":{"status":"ok","timestamp":1696562606905,"user_tz":240,"elapsed":46,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["# This was assigned under the __init__() method\n","selfembdrop = nn.Dropout(.4)"]},{"cell_type":"code","source":["z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NT3YAjeRs92c","executionInfo":{"status":"ok","timestamp":1696562606905,"user_tz":240,"elapsed":45,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"ca2ab547-3388-4640-f481-bff7edb3fa85"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1677, -1.6355, -0.9113,  0.8843,  1.5710,  0.8027,  1.0104,  2.5019,\n","          1.2791,  0.6054,  1.3902, -0.4989,  0.6718, -0.6247, -1.5155,  0.3390,\n","         -1.1460],\n","        [-0.1508, -0.1471,  1.3686, -0.3555, -0.2774,  0.1099, -0.5506,  1.0596,\n","          0.3595,  0.4859, -1.6289, -0.6530,  0.6718, -0.1082,  0.0500,  0.0956,\n","         -0.7517],\n","        [-0.6778, -0.1558, -3.2439, -1.9364, -0.5427, -0.5546, -2.1623, -0.7389,\n","          0.9051,  0.0613, -0.6952, -2.4025,  0.6718, -0.1082,  0.0500,  0.0956,\n","         -0.7517],\n","        [ 0.7398, -0.7913, -0.9718,  1.3142, -0.6902,  0.5929, -2.2412, -0.3437,\n","          0.4038,  0.3001, -0.0516,  0.9254,  0.6541,  1.1388,  0.3222,  1.2124,\n","          0.4271]], grad_fn=<CatBackward0>)"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["# dropout layer randomly drops out the  values and also scales the values with 1/(1-p)\n","0.9144 * (1/(1-0.4))\n","# https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n","# Furthermore, the outputs are scaled by a factor of (1/(1-p))\n","#  during training. This means that during evaluation the module simply computes an identity function."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvosBffduPHY","executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":42,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"c25abe0d-d2e4-4809-f9c6-2a8c60c7f1b5"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.524"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["# 0.9144 got converted to 1.5239"],"metadata":{"id":"nPsbHNQNvMqz","executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":38,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{"id":"6S19pEMjjmYv","outputId":"fb806f71-9bd4-441b-d1c4-80ae7fa77149","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":37,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2796, -2.7259, -0.0000,  1.4739,  2.6183,  0.0000,  1.6841,  4.1699,\n","          0.0000,  1.0090,  2.3170, -0.8316,  0.0000, -0.0000, -2.5259,  0.5650,\n","         -1.9099],\n","        [-0.2514, -0.2452,  0.0000, -0.5926, -0.0000,  0.0000, -0.9176,  1.7659,\n","          0.5991,  0.8099, -0.0000, -0.0000,  0.0000, -0.1803,  0.0833,  0.0000,\n","         -1.2528],\n","        [-1.1297, -0.2596, -0.0000, -3.2273, -0.0000, -0.0000, -3.6038, -0.0000,\n","          1.5085,  0.0000, -0.0000, -0.0000,  1.1197, -0.0000,  0.0000,  0.1594,\n","         -1.2528],\n","        [ 0.0000, -1.3188, -1.6196,  2.1904, -1.1504,  0.9881, -0.0000, -0.0000,\n","          0.6731,  0.0000, -0.0860,  1.5424,  0.0000,  1.8980,  0.5370,  0.0000,\n","          0.0000]], grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":54}],"source":["k = selfembdrop(z) # every call to dropout will randomly zero out different values\n","k"]},{"cell_type":"markdown","metadata":{"id":"p1k0xlFLjmYv"},"source":["<div class=\"alert alert-danger\"><strong>This is how the categorical embeddings are passed into the layers.</strong></div>"]},{"cell_type":"code","source":["## Batch Normalization\n","# With Learnable Parameters\n","m = nn.BatchNorm1d(10) # 10 is number of features\n","torch.manual_seed(33)\n","\n","inp = torch.randn(3, 10) # normally distributed 3 rows 10 columns means 10 features\n","inp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YC2aMczxT-5r","executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":34,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"7017ba6c-f791-4b6e-a5b5-0c70fbe7a615"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.6014,  0.1087, -0.4499,  0.7841,  0.6550, -0.3062,  1.3935,  0.0631,\n","         -1.2514,  1.2745],\n","        [ 0.4777, -0.4516,  0.1392, -1.5146, -1.5037, -0.6517, -1.0364,  0.3204,\n","         -1.0311,  0.7873],\n","        [-1.3096, -0.3365, -0.2929, -1.7431, -0.2974,  0.3986,  0.4957,  0.8755,\n","          0.5996,  0.1281]])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["outp = m(inp)\n","outp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRGdMNSDUM37","executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":31,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"4b0ec0ba-e4e5-4354-895c-bd27c09576b7"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.7767,  1.3871, -0.9984,  1.4095,  1.1740, -0.2739,  1.1057, -1.0518,\n","         -0.8364,  1.1591],\n","        [ 0.6351, -0.9318,  1.3665, -0.6046, -1.2698, -1.0645, -1.3164, -0.2927,\n","         -0.5694,  0.1221],\n","        [-1.4118, -0.4553, -0.3681, -0.8048,  0.0958,  1.3385,  0.2107,  1.3445,\n","          1.4058, -1.2812]], grad_fn=<NativeBatchNormBackward0>)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["0.7767 + 0.6351 -1.4118"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTukiuVBUg12","executionInfo":{"status":"ok","timestamp":1696562606906,"user_tz":240,"elapsed":27,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"f74a25c6-5e67-48a3-9405-2df0ce4bc322"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["#nn.Linear(in_features: int, out_features: int,)"],"metadata":{"id":"4e1X_pVQXYKy","executionInfo":{"status":"ok","timestamp":1696562606907,"user_tz":240,"elapsed":24,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","execution_count":59,"metadata":{"collapsed":true,"id":"g5yd9pwDjmYw","executionInfo":{"status":"ok","timestamp":1696562606907,"user_tz":240,"elapsed":24,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["class TabularModel(nn.Module):\n","\n","    # embedding sizes,  number of Continuous features, output size,\n","    # layers = [50,100,200] being used and finally the probability for dropout layer\n","    # will default it to, let's say, 0.5.\n","\n","    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n","        super().__init__()\n","        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","        self.emb_drop = nn.Dropout(p)\n","        self.bn_cont = nn.BatchNorm1d(n_cont)\n","\n","        layerlist = []\n","        n_emb = sum((nf for ni,nf in emb_szs)) # this is the sum of 12,1,4\n","        n_in = n_emb + n_cont\n","\n","        for i in layers:\n","            layerlist.append(nn.Linear(n_in,i))\n","            layerlist.append(nn.ReLU(inplace=True))\n","            layerlist.append(nn.BatchNorm1d(i))\n","            layerlist.append(nn.Dropout(p))\n","            n_in = i\n","        layerlist.append(nn.Linear(layers[-1],out_sz))\n","\n","        self.layers = nn.Sequential(*layerlist)\n","\n","    def forward(self, x_cat, x_cont):\n","        # categotical values\n","        embeddings = []\n","        for i,e in enumerate(self.embeds):\n","            embeddings.append(e(x_cat[:,i]))\n","        x = torch.cat(embeddings, 1)\n","        x = self.emb_drop(x)\n","        # continuous values\n","        x_cont = self.bn_cont(x_cont)\n","        x = torch.cat([x, x_cont], 1)\n","        x = self.layers(x)\n","        return x"]},{"cell_type":"code","source":["conts.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfAZ-RnMmiN9","executionInfo":{"status":"ok","timestamp":1696562606907,"user_tz":240,"elapsed":23,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"66aef801-151f-4a85-a9ed-74958d1174b4"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([120000, 6])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","execution_count":61,"metadata":{"collapsed":true,"id":"HOZFH5wbjmYw","executionInfo":{"status":"ok","timestamp":1696562606907,"user_tz":240,"elapsed":20,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["#     def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n","\n","torch.manual_seed(33)\n","model = TabularModel(emb_szs, conts.shape[1], 1, [200,100], p=0.4)"]},{"cell_type":"code","source":["\n","catz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_FcZ8bb62zO","executionInfo":{"status":"ok","timestamp":1696562606907,"user_tz":240,"elapsed":19,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"3cff9679-9229-41d7-c2c7-70d4ef490903"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4,  0,  1],\n","        [11,  0,  2],\n","        [ 7,  0,  2],\n","        [17,  1,  3]])"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["# https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16\n","# During the training the parameters of the nn.Embedding layer in a neural network are adjusted in\n","# order to optimize the performance of the model. Specifically, the embedding matrix is updated via backpropagation to minimize the loss function. This can be thought of as learning a mapping from discrete input tokens (such as words) to continuous embedding vectors in a high-dimensional space, where the vectors are optimised to represent the meaning or context of the input tokens in relation to the task the model is trained for (e.g. text generation, language translation)."],"metadata":{"id":"AKOkRGuEDst-","executionInfo":{"status":"ok","timestamp":1696562607100,"user_tz":240,"elapsed":209,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# This happens inside the forward() method\n","embeddingz = []\n","for i,e in (enumerate(model.embeds)):\n","    embeddingz.append(e(catz[:,i])) # by taking each column from all rows and getting a embedding tensor\n","embeddingz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef3aecSD5d9I","executionInfo":{"status":"ok","timestamp":1696562607100,"user_tz":240,"elapsed":29,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"1dbd1de6-76b4-42f3-8591-7c19020c10ac"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[-1.1712, -1.0707,  1.5110, -1.4429, -0.3396, -1.6925, -0.3451,  1.3243,\n","           0.1380, -0.7729,  0.9246,  0.5713],\n","         [ 0.4214,  0.9682, -0.9452,  1.9558,  0.9899,  1.0497,  1.0668, -1.0889,\n","          -1.4327, -2.1288, -0.0278, -0.6627],\n","         [ 1.8679, -0.2671,  0.0272, -1.2297, -0.7697, -0.0064,  0.7389, -1.3731,\n","          -0.6959, -1.0619, -0.4985, -1.1778],\n","         [-0.3787, -2.2401, -1.1068, -1.3562,  0.1844,  0.5235, -1.7119, -0.2419,\n","          -0.8690, -0.5548, -0.4396,  1.4136]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[-0.0216],\n","         [-0.0216],\n","         [-0.0216],\n","         [ 0.3949]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[ 0.4373, -0.7895,  1.2179,  0.4470],\n","         [ 1.6881, -1.5008, -1.5567,  0.5621],\n","         [ 1.6881, -1.5008, -1.5567,  0.5621],\n","         [ 0.6990, -0.1895, -2.1106, -1.7561]], grad_fn=<EmbeddingBackward0>)]"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":[],"metadata":{"id":"PqMgmCmW3LMf","executionInfo":{"status":"ok","timestamp":1696562607100,"user_tz":240,"elapsed":26,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","execution_count":65,"metadata":{"id":"EOMZ1IDgjmYw","outputId":"12f431fe-714c-4076-c0ea-f7136a0a1b02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562607101,"user_tz":240,"elapsed":27,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TabularModel(\n","  (embeds): ModuleList(\n","    (0): Embedding(24, 12)\n","    (1): Embedding(2, 1)\n","    (2): Embedding(7, 4)\n","  )\n","  (emb_drop): Dropout(p=0.4, inplace=False)\n","  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layers): Sequential(\n","    (0): Linear(in_features=23, out_features=200, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=200, out_features=100, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): Dropout(p=0.4, inplace=False)\n","    (8): Linear(in_features=100, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":65}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"caqKIxZejmYw"},"source":["## Define loss function & optimizer\n","\n","PyTorch does not offer a built-in <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE Loss</a> function, and it would be nice to see this in place of MSE.<br>\n","For this reason, we'll simply apply the <tt>torch.sqrt()</tt> function to the output of MSELoss during training."]},{"cell_type":"code","execution_count":66,"metadata":{"collapsed":true,"id":"WAnDv3ykjmYx","executionInfo":{"status":"ok","timestamp":1696562607101,"user_tz":240,"elapsed":23,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["criterion = nn.MSELoss()  # we'll convert this to RMSE later\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"5gWj5HB-jmYx"},"source":["## Perform train/test splits\n","At this point our batch size is the entire dataset of 120,000 records. This will take a long time to train, so you might consider reducing this. We'll use 60,000. Recall that our tensors are already randomly shuffled."]},{"cell_type":"code","execution_count":67,"metadata":{"collapsed":true,"id":"mwJt8iQTjmYx","executionInfo":{"status":"ok","timestamp":1696562607101,"user_tz":240,"elapsed":20,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["batch_size = 30000 # only using 30000 samples as RAM is not enough to run more epochs on entire set of data.\n","test_size = int(batch_size * .2)\n","\n","cat_train = cats[:batch_size-test_size]\n","cat_test = cats[batch_size-test_size:batch_size]\n","con_train = conts[:batch_size-test_size]\n","con_test = conts[batch_size-test_size:batch_size]\n","y_train = y[:batch_size-test_size]\n","y_test = y[batch_size-test_size:batch_size]"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"cGfFP7uvjmYx","outputId":"e5450816-13f9-4cef-e662-8fa9f1310aa8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562607101,"user_tz":240,"elapsed":20,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["24000"]},"metadata":{},"execution_count":68}],"source":["len(cat_train)"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"oVqBUh9ajmYy","outputId":"60785944-2e2d-4272-8294-c17fd20a3d28","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562607101,"user_tz":240,"elapsed":16,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6000"]},"metadata":{},"execution_count":69}],"source":["len(cat_test)"]},{"cell_type":"markdown","metadata":{"id":"5HJCeMvUjmYy"},"source":["## Train the model\n","Expect this to take 30 minutes or more! We've added code to tell us the duration at the end."]},{"cell_type":"code","source":[],"metadata":{"id":"-I7IaSRRw7jB","executionInfo":{"status":"ok","timestamp":1696562607102,"user_tz":240,"elapsed":14,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["y_pred = model.forward(cat_train, con_train)\n","\n","y_pred = model(cat_train, con_train)\n","gave me same output but https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690\n","You should avoid calling Module.forward. The difference is that all the hooks are dispatched in the __call__ function, so if you call .forward and have hooks in your model, the hooks won’t have any effect\n","\n","Hooks are functions that help to update the gradients, inputs or outputs dynamically. That is I can change the behaviour of the Neural Network even when I am training it. Hooks are used in two places. On tensors. On torch.nn.Modules.\n","\n","\n","\n","https://medium.com/analytics-vidhya/pytorch-hooks-5909c7636fb#:~:text=Hooks%20are%20functions%20that%20help,On%20torch.nn.Modules\n","\n"],"metadata":{"id":"iATnOzbwy_s0"}},{"cell_type":"code","execution_count":70,"metadata":{"id":"FLcL6B40jmYy","outputId":"3aca79db-d028-45bc-bfe5-19c1f091255f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562687358,"user_tz":240,"elapsed":80269,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:   1  loss: 12.50839520\n","epoch:  26  loss: 10.86515236\n","epoch:  51  loss: 10.21556950\n","epoch:  76  loss: 9.73605919\n","epoch: 101  loss: 9.20095158\n","epoch: 126  loss: 8.43457603\n","epoch: 151  loss: 7.41893578\n","epoch: 176  loss: 6.25202227\n","epoch: 201  loss: 5.05875158\n","epoch: 226  loss: 4.24312782\n","epoch: 251  loss: 3.87326407\n","epoch: 276  loss: 3.78485823\n","epoch: 301  loss: 3.70447493\n","epoch: 326  loss: 3.61585879\n","epoch: 350  loss: 3.59118438\n","\n","Duration: 80 seconds\n"]}],"source":["import time\n","start_time = time.time()\n","\n","epochs = 350\n","losses = []\n","\n","for i in range(epochs):\n","    i+=1\n","    y_pred = model(cat_train, con_train)\n","    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n","    losses.append(loss.detach().numpy())\n","\n","    # a neat trick to save screen space:\n","    if i%25 == 1:\n","        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n","print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"]},{"cell_type":"markdown","metadata":{"id":"RNAdWIMKjmYz"},"source":["## Plot the loss function"]},{"cell_type":"code","source":["embeddingz = []\n","for i,e in (enumerate(model.embeds)):\n","    embeddingz.append(e(catz[:,i])) # by taking each column from all rows and getting a embedding tensor\n","embeddingz"],"metadata":{"id":"ydtxAvzRTVnJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562687358,"user_tz":240,"elapsed":45,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"5216a2df-2347-44f5-c0bd-912e2510250c"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[-0.9942, -0.9172,  1.3805, -1.3067, -0.3602, -1.5858, -0.2739,  1.2086,\n","           0.0335, -0.5748,  0.7196,  0.5223],\n","         [ 0.3928,  0.8912, -0.7838,  1.8483,  0.7675,  0.9590,  0.8752, -0.9525,\n","          -1.2566, -1.9736, -0.0594, -0.5837],\n","         [ 1.7041, -0.1522,  0.0416, -1.1213, -0.7127,  0.0254,  0.6377, -1.2357,\n","          -0.5593, -1.0085, -0.4166, -1.1641],\n","         [-0.4695, -2.0910, -0.9773, -1.2312,  0.1915,  0.4778, -1.5756, -0.1652,\n","          -0.7062, -0.4692, -0.3504,  1.2919]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[-0.1381],\n","         [-0.1381],\n","         [-0.1381],\n","         [ 0.2543]], grad_fn=<EmbeddingBackward0>),\n"," tensor([[ 0.6005, -0.7559,  1.2194,  0.4867],\n","         [ 1.5077, -1.3356, -1.4639,  0.4404],\n","         [ 1.5077, -1.3356, -1.4639,  0.4404],\n","         [ 0.7180, -0.2485, -1.9951, -1.6250]], grad_fn=<EmbeddingBackward0>)]"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","execution_count":72,"metadata":{"id":"vTS4Tlf7jmYz","outputId":"d39620d7-64e8-47f9-b46d-c7367428d304","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"ok","timestamp":1696562687568,"user_tz":240,"elapsed":248,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.plot(range(epochs), losses)\n","plt.ylabel('RMSE Loss')\n","plt.xlabel('epoch');"]},{"cell_type":"markdown","metadata":{"id":"19H3MTn2jmY0"},"source":["## Validate the model\n","Here we want to run the entire test set through the model, and compare it to the known labels.<br>\n","For this step we don't want to update weights and biases, so we set <tt>torch.no_grad()</tt>"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"nmpdj73SjmY0","outputId":"e3792b9a-5da1-4559-ebb8-0b6b68afd8d6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562687817,"user_tz":240,"elapsed":261,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 3.51792979\n"]}],"source":["# TO EVALUATE THE ENTIRE TEST SET\n","with torch.no_grad():\n","    y_val = model(cat_test, con_test)\n","    loss = torch.sqrt(criterion(y_val, y_test))\n","print(f'RMSE: {loss:.8f}')"]},{"cell_type":"markdown","metadata":{"id":"eIUaOWQKjmY0"},"source":["This means that on average, predicted values are within &plusmn;$3.31 of the actual value.\n","\n","Now let's look at the first 50 predicted values:"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"_VaPEOFSjmY0","outputId":"f8b18ee1-2d04-45fb-d43c-db3eaa47aacd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696562687818,"user_tz":240,"elapsed":35,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["   PREDICTED   ACTUAL     DIFF\n"," 1.   4.1551   4.9000   0.7449\n"," 2.  12.6283   8.5000   4.1283\n"," 3.   6.6570   4.9000   1.7570\n"," 4.  19.5530  14.9000   4.6530\n"," 5.   8.4256   9.7000   1.2744\n"," 6.  26.9186  30.2700   3.3514\n"," 7.   2.1802   5.3000   3.1198\n"," 8.   7.9414   5.3000   2.6414\n"," 9.   4.4581   6.1000   1.6419\n","10.   6.6859   6.1000   0.5859\n","11.   9.8021   9.3000   0.5021\n","12.   5.5637   5.3000   0.2637\n","13.   7.0520   4.5000   2.5520\n","14.  10.5503  33.8700  23.3197\n","15.   6.1226   5.7000   0.4226\n","16.   4.4511   5.3000   0.8489\n","17.  11.2227  10.1000   1.1227\n","18.   5.3662   6.5000   1.1338\n","19.   5.9599   5.7000   0.2599\n","20.  10.2050  12.9000   2.6950\n","21.   4.8202   4.9000   0.0798\n","22.   9.5724   7.7000   1.8724\n","23.   4.3698   4.5000   0.1302\n","24.   7.7404   6.5000   1.2404\n","25.  11.5369  10.1000   1.4369\n","26.   8.1115  10.5000   2.3885\n","27.   9.6788  12.5000   2.8212\n","28.   6.3647   4.9000   1.4647\n","29.   8.2660   5.7000   2.5660\n","30.   7.0327   8.1000   1.0673\n","31.  11.9191  12.9000   0.9809\n","32.   3.1518   8.1000   4.9482\n","33.   5.7313   4.1000   1.6313\n","34.   5.3266   4.9000   0.4266\n","35.   2.4674   6.5000   4.0326\n","36.   9.9792  10.5000   0.5208\n","37.   7.6621   6.5000   1.1621\n","38.   7.0848   6.5000   0.5848\n","39.   6.0256   5.3000   0.7256\n","40.   9.9706   8.5000   1.4706\n","41.  14.2336  16.5000   2.2664\n","42.  14.8695  12.1000   2.7695\n","43.   2.0537   6.5000   4.4463\n","44.   5.6362   2.9000   2.7362\n","45.  10.1973   4.9000   5.2973\n","46.   4.4759   6.1000   1.6241\n","47.   7.2975   6.9000   0.3975\n","48.  10.2833  10.5000   0.2167\n","49.   7.1969   6.1000   1.0969\n","50.   2.8625   4.5000   1.6375\n"]}],"source":["print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n","for i in range(50):\n","    diff = np.abs(y_val[i].item()-y_test[i].item())\n","    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"]},{"cell_type":"code","source":[],"metadata":{"id":"41W5qmniuVEn","executionInfo":{"status":"ok","timestamp":1696562687819,"user_tz":240,"elapsed":30,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3fzkS1JwuVYr","executionInfo":{"status":"ok","timestamp":1696562687820,"user_tz":240,"elapsed":29,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ndC9VQs9jmY1"},"source":["So while many predictions were off by a few cents, some were off by \\\\$19.00. Feel free to change the batch size, test size, and number of epochs to obtain a better model."]},{"cell_type":"markdown","metadata":{"id":"amUX0UW6jmY1"},"source":["## Save the model\n","We can save a trained model to a file in case we want to come back later and feed new data through it. The best practice is to save the state of the model (weights & biases) and not the full definition. Also, we want to ensure that only a trained model is saved, to prevent overwriting a previously saved model with an untrained one.<br>For more information visit <a href='https://pytorch.org/tutorials/beginner/saving_loading_models.html'>https://pytorch.org/tutorials/beginner/saving_loading_models.html</a>"]},{"cell_type":"code","execution_count":75,"metadata":{"collapsed":true,"id":"YUXdAFTSjmY1","executionInfo":{"status":"ok","timestamp":1696562687820,"user_tz":240,"elapsed":28,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["# Make sure to save the model only after the training has happened!\n","if len(losses) == epochs:\n","    #torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n","    # just avoid rewriting the saved model.\n","    pass\n","else:\n","    print('Model has not been trained. Consider loading a trained model instead.')"]},{"cell_type":"markdown","metadata":{"id":"kXO6P0l3jmY1"},"source":["## Loading a saved model (starting from scratch)\n","We can load the trained weights and biases from a saved model. If we've just opened the notebook, we'll have to run standard imports and function definitions. To demonstrate, restart the kernel before proceeding."]},{"cell_type":"code","execution_count":76,"metadata":{"collapsed":true,"id":"sXRP2Tn4jmY1","executionInfo":{"status":"ok","timestamp":1696562687821,"user_tz":240,"elapsed":28,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","\n","def haversine_distance(df, lat1, long1, lat2, long2):\n","    r = 6371\n","    phi1 = np.radians(df[lat1])\n","    phi2 = np.radians(df[lat2])\n","    delta_phi = np.radians(df[lat2]-df[lat1])\n","    delta_lambda = np.radians(df[long2]-df[long1])\n","    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n","    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n","    return r * c\n","\n","class TabularModel(nn.Module):\n","    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n","        super().__init__()\n","        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n","        self.emb_drop = nn.Dropout(p)\n","        # batch normalization continous values\n","        self.bn_cont = nn.BatchNorm1d(n_cont)\n","        layerlist = []\n","        n_emb = sum((nf for ni,nf in emb_szs))\n","        n_in = n_emb + n_cont\n","        for i in layers:\n","            layerlist.append(nn.Linear(n_in,i))\n","            layerlist.append(nn.ReLU(inplace=True))\n","            layerlist.append(nn.BatchNorm1d(i))\n","            layerlist.append(nn.Dropout(p))\n","            n_in = i\n","        layerlist.append(nn.Linear(layers[-1],out_sz))\n","        self.layers = nn.Sequential(*layerlist)\n","    def forward(self, x_cat, x_cont):\n","        embeddings = []\n","        for i,e in enumerate(self.embeds):\n","            embeddings.append(e(x_cat[:,i]))\n","        x = torch.cat(embeddings, 1)\n","        x = self.emb_drop(x)\n","        x_cont = self.bn_cont(x_cont)\n","        x = torch.cat([x, x_cont], axis= 1)\n","        return self.layers(x)"]},{"cell_type":"markdown","metadata":{"id":"QzGXcs0wjmY2"},"source":["Now define the model. Before we can load the saved settings, we need to instantiate our TabularModel with the parameters we used before (embedding sizes, number of continuous columns, output size, layer sizes, and dropout layer p-value)."]},{"cell_type":"code","execution_count":77,"metadata":{"collapsed":true,"id":"4lI-XNlSjmY2","executionInfo":{"status":"ok","timestamp":1696562687821,"user_tz":240,"elapsed":27,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["emb_szs = [(24, 12), (2, 1), (7, 4)]\n","model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)\n"]},{"cell_type":"markdown","metadata":{"id":"BQtWNgLjjmY2"},"source":["Once the model is set up, loading the saved settings is a snap."]},{"cell_type":"code","source":["help(model2.eval)\n","# This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fogIZLrT6sDM","executionInfo":{"status":"ok","timestamp":1696562808423,"user_tz":240,"elapsed":178,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"542ed406-22c1-4061-d26b-43e45b4f37f6"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on method eval in module torch.nn.modules.module:\n","\n","eval() -> ~T method of __main__.TabularModel instance\n","    Sets the module in evaluation mode.\n","    \n","    This has any effect only on certain modules. See documentations of\n","    particular modules for details of their behaviors in training/evaluation\n","    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n","    etc.\n","    \n","    This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n","    \n","    See :ref:`locally-disable-grad-doc` for a comparison between\n","    `.eval()` and several similar mechanisms that may be confused with it.\n","    \n","    Returns:\n","        Module: self\n","\n"]}]},{"cell_type":"code","source":["# above says\n","\n","#This has any effect only on certain modules. See documentations of\n","#    particular modules for details of their behaviors in training/evaluation\n","#    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n","#    etc."],"metadata":{"id":"_SeZJaJ874hD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LuxW5xan806F"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":79,"metadata":{"id":"a__GMoCIjmY3","executionInfo":{"status":"ok","timestamp":1696562812406,"user_tz":240,"elapsed":200,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n","model2.eval() # be sure to run this step!"]},{"cell_type":"markdown","metadata":{"id":"X_HiH5fOjmY3"},"source":["Next we'll define a function that takes in new parameters from the user, performs all of the preprocessing steps above, and passes the new data through our trained model."]},{"cell_type":"code","source":["df['Weekday'].cat.categories"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GBS0DkxF2_7","executionInfo":{"status":"ok","timestamp":1696562927892,"user_tz":240,"elapsed":189,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"d415254c-a773-47b7-9416-f7504b3a8058"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":[],"metadata":{"id":"zhGxyspoB-8g","executionInfo":{"status":"ok","timestamp":1696563047086,"user_tz":240,"elapsed":184,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["# in below Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')\n","# = [0,1,2,3,4,5,6]\n","\n","#dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n","#                                            [0,1,2,3,4,5,6]).astype('int64')\n","    # CREATE CAT AND CONT TENSORS"],"metadata":{"id":"gj3oI2AuGv1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":84,"metadata":{"collapsed":true,"id":"Xyi7ZfD7jmY3","executionInfo":{"status":"ok","timestamp":1696563050951,"user_tz":240,"elapsed":156,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[],"source":["def test_data(mdl): # pass in the name of the new model\n","    # INPUT NEW DATA\n","    print(\"hrllo\")\n","    plat = float(input('What is the pickup latitude?  '))\n","    plong = float(input('What is the pickup longitude? '))\n","    dlat = float(input('What is the dropoff latitude?  '))\n","    dlong = float(input('What is the dropoff longitude? '))\n","    psngr = int(input('How many passengers? '))\n","    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n","\n","    # PREPROCESS THE DATA\n","    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n","         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n","    dfx = pd.DataFrame(dfx_dict, index=[0])\n","    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n","                                        'dropoff_latitude', 'dropoff_longitude')\n","    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n","\n","    # We can skip the .astype(category) step since our fields are small,\n","    # and encode them right away\n","    dfx['Hour'] = dfx['EDTdate'].dt.hour\n","    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1)\n","    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n","    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n","                                            [0,1,2,3,4,5,6]).astype('int64')\n","    # CREATE CAT AND CONT TENSORS\n","    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n","    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n","                 'dropoff_longitude', 'passenger_count', 'dist_km']\n","    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n","    xcats = torch.tensor(xcats, dtype=torch.int64)\n","    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n","    xconts = torch.tensor(xconts, dtype=torch.float)\n","    print(xcats)\n","    print(xconts)\n","\n","    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n","    with torch.no_grad():\n","        z = mdl(xcats, xconts)\n","    print(f'\\nThe predicted fare amount is ${z.item():.2f}')"]},{"cell_type":"markdown","metadata":{"id":"5Rvi3OoNjmY3"},"source":["## Feed new data through the trained model\n","For convenience, here are the max and min values for each of the variables:\n","<table style=\"display: inline-block\">\n","<tr><th>Column</th><th>Minimum</th><th>Maximum</th></tr>\n","<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n","<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n","<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n","<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n","<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n","<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>"]},{"cell_type":"markdown","metadata":{"id":"QyiGf7xRjmY4"},"source":["<strong>Use caution!</strong> The distance between 1 degree of latitude (from 40 to 41) is 111km (69mi) and between 1 degree of longitude (from -73 to -74) is 85km (53mi). The longest cab ride in the dataset spanned a difference of only 0.243 degrees latitude and 0.284 degrees longitude. The mean difference for both latitude and longitude was about 0.02. To get a fair prediction, use values that fall close to one another."]},{"cell_type":"code","source":["#pickup_datetime\tfare_amount\tfare_class\tpickup_longitude\tpickup_latitude\tdropoff_longitude\tdropoff_latitude\tpassenger_count\n","#2010-04-19 08:17:56 UTC\t6.5\t0\t-73.992365\t40.730521\t-73.975499\t40.744746"],"metadata":{"id":"4n1D4ZHsMe3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","z = test_data(model)\n","hrllo\n","What is the pickup latitude?  40.730521\n","What is the pickup longitude? -73.992365\n","What is the dropoff latitude?  40.744746\n","What is the dropoff longitude? -73.975499\n","How many passengers? 2\n","What is the pickup date and time?\n","Format as YYYY-MM-DD HH:MM:SS     2010-04-19 08:17:56\n","tensor([[8, 0, 1]])\n","tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   2.0000,   2.1263]])\n","---------------------------------------------------------------------------\n","ValueError                                Traceback (most recent call last)\n","<ipython-input-74-243ea07c1225> in <cell line: 1>()\n","----> 1 z = test_data(model)\n","\n","6 frames\n","<ipython-input-73-669fdd699ab3> in test_data(mdl)\n","     37     # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n","     38     with torch.no_grad():\n","---> 39         z = mdl(xcats, xconts)\n","     40     print(f'\\nThe predicted fare amount is ${z.item():.2f}')\n","\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\n","   1499                 or _global_backward_pre_hooks or _global_backward_hooks\n","   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501             return forward_call(*args, **kwargs)\n","   1502         # Do not call functions when jit is used\n","   1503         full_backward_hooks, non_full_backward_hooks = [], []\n","\n","<ipython-input-53-737cf6dbcea9> in forward(self, x_cat, x_cont)\n","     32         x = self.emb_drop(x)\n","     33\n","---> 34         x_cont = self.bn_cont(x_cont)\n","     35         x = torch.cat([x, x_cont], 1)\n","     36         x = self.layers(x)\n","\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\n","   1499                 or _global_backward_pre_hooks or _global_backward_hooks\n","   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501             return forward_call(*args, **kwargs)\n","   1502         # Do not call functions when jit is used\n","   1503         full_backward_hooks, non_full_backward_hooks = [], []\n","\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)\n","    169         used for normalization (i.e. in eval mode when buffers are not None).\n","    170         \"\"\"\n","--> 171         return F.batch_norm(\n","    172             input,\n","    173             # If buffers are not to be tracked, ensure that they won't be updated\n","\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n","   2446         )\n","   2447     if training:\n","-> 2448         _verify_batch_size(input.size())\n","   2449\n","   2450     return torch.batch_norm(\n","\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py in _verify_batch_size(size)\n","   2414         size_prods *= size[i + 2]\n","   2415     if size_prods == 1:\n","-> 2416         raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n","   2417\n","   2418\n","\n","ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 6])'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"5esH_t36wGNy","outputId":"0b29adf8-469a-44ea-f152-1b52580daa24","executionInfo":{"status":"ok","timestamp":1695270113600,"user_tz":240,"elapsed":384,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nz = test_data(model)\\nhrllo\\nWhat is the pickup latitude?  40.730521\\nWhat is the pickup longitude? -73.992365\\nWhat is the dropoff latitude?  40.744746\\nWhat is the dropoff longitude? -73.975499\\nHow many passengers? 2\\nWhat is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     2010-04-19 08:17:56\\ntensor([[8, 0, 1]])\\ntensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   2.0000,   2.1263]])\\n---------------------------------------------------------------------------\\nValueError                                Traceback (most recent call last)\\n<ipython-input-74-243ea07c1225> in <cell line: 1>()\\n----> 1 z = test_data(model)\\n\\n6 frames\\n<ipython-input-73-669fdd699ab3> in test_data(mdl)\\n     37     # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\\n     38     with torch.no_grad():\\n---> 39         z = mdl(xcats, xconts)\\n     40     print(f\\'\\nThe predicted fare amount is ${z.item():.2f}\\')\\n\\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\\n   1499                 or _global_backward_pre_hooks or _global_backward_hooks\\n   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\\n-> 1501             return forward_call(*args, **kwargs)\\n   1502         # Do not call functions when jit is used\\n   1503         full_backward_hooks, non_full_backward_hooks = [], []\\n\\n<ipython-input-53-737cf6dbcea9> in forward(self, x_cat, x_cont)\\n     32         x = self.emb_drop(x)\\n     33 \\n---> 34         x_cont = self.bn_cont(x_cont)\\n     35         x = torch.cat([x, x_cont], 1)\\n     36         x = self.layers(x)\\n\\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)\\n   1499                 or _global_backward_pre_hooks or _global_backward_hooks\\n   1500                 or _global_forward_hooks or _global_forward_pre_hooks):\\n-> 1501             return forward_call(*args, **kwargs)\\n   1502         # Do not call functions when jit is used\\n   1503         full_backward_hooks, non_full_backward_hooks = [], []\\n\\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)\\n    169         used for normalization (i.e. in eval mode when buffers are not None).\\n    170         \"\"\"\\n--> 171         return F.batch_norm(\\n    172             input,\\n    173             # If buffers are not to be tracked, ensure that they won\\'t be updated\\n\\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\\n   2446         )\\n   2447     if training:\\n-> 2448         _verify_batch_size(input.size())\\n   2449 \\n   2450     return torch.batch_norm(\\n\\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py in _verify_batch_size(size)\\n   2414         size_prods *= size[i + 2]\\n   2415     if size_prods == 1:\\n-> 2416         raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\\n   2417 \\n   2418 \\n\\nValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 6])'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["# important\n","# z = test_data(model)\n","# did not work till model.eval is called\n","#  as in above at ---> 34         x_cont = self.bn_cont(x_cont)\n","# as it  assumes it is training and training fails with the error  return F.batch_norm(\n","#   172             input,\n","#   173             # If buffers are not to be tracked, ensure that they won't be updated\n"],"metadata":{"id":"-TCEFAy569Dj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# it is failing at BatchNormalization step as if eval is not called it assumes training is going on\n","# but that layer is receiving only one value  per feature and cannot do any normalization\n","# as for normalization it needs batch of values per feature."],"metadata":{"id":"PfqZKUhrGReq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIuogUPc62-P","executionInfo":{"status":"ok","timestamp":1695269260713,"user_tz":240,"elapsed":160,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"ac2983c6-cc85-4526-ad93-4387cbb8c53f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TabularModel(\n","  (embeds): ModuleList(\n","    (0): Embedding(24, 12)\n","    (1): Embedding(2, 1)\n","    (2): Embedding(7, 4)\n","  )\n","  (emb_drop): Dropout(p=0.4, inplace=False)\n","  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layers): Sequential(\n","    (0): Linear(in_features=23, out_features=200, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=200, out_features=100, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): Dropout(p=0.4, inplace=False)\n","    (8): Linear(in_features=100, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# help(model.eval)\n","# This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n","z = test_data(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xW2A8tO97FaC","executionInfo":{"status":"ok","timestamp":1695270212985,"user_tz":240,"elapsed":73247,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"89daa30f-8175-4b4b-a97c-1607e62aa053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hrllo\n","What is the pickup latitude?  40.730521\n","What is the pickup longitude? -73.992365\n","What is the dropoff latitude?  40.744746\n","What is the dropoff longitude? -73.975499\n","How many passengers? 2\n","What is the pickup date and time?\n","Format as YYYY-MM-DD HH:MM:SS     2010-04-19 08:17:56\n","tensor([[8, 0, 1]])\n","tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   2.0000,   2.1263]])\n","\n","The predicted fare amount is $7.24\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsW08ZRujmY4","outputId":"e6034b7d-46f9-4e5a-88e7-1156fea54f3b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695268680926,"user_tz":240,"elapsed":31449,"user":{"displayName":"s k","userId":"03459268313336948614"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["hrllo\n","What is the pickup latitude?  40.730521\n","What is the pickup longitude? -73.992365\n","What is the dropoff latitude?  40.744746\n","What is the dropoff longitude? -73.975499\n","How many passengers? 2\n","What is the pickup date and time?\n","Format as YYYY-MM-DD HH:MM:SS     2010-04-19 08:17:56\n","tensor([[8, 0, 1]])\n","tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   2.0000,   2.1263]])\n","\n","The predicted fare amount is $7.61\n"]}],"source":["z = test_data(model2)"]},{"cell_type":"code","source":["z = test_data(model2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVbQMICkMwNz","executionInfo":{"status":"ok","timestamp":1695139753026,"user_tz":240,"elapsed":56535,"user":{"displayName":"s k","userId":"03459268313336948614"}},"outputId":"7630bc5e-a906-4d15-801c-6eef853f65b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hrllo\n","What is the pickup latitude?  40.730521\n","What is the pickup longitude? -73.992365\n","What is the dropoff latitude?  40.744746\n","What is the dropoff longitude? -73.975499\n","How many passengers? 1\n","What is the pickup date and time?\n","Format as YYYY-MM-DD HH:MM:SS     2010-04-19 08:17:56\n","\n","The predicted fare amount is $7.37\n"]}]},{"cell_type":"markdown","metadata":{"id":"2MUzc46KjmY4"},"source":["## Great job!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}